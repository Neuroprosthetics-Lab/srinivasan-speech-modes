{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import numpy as np\n",
    "from functions import get_audio_onset_offset\n",
    "import os\n",
    "from pathlib import Path\n",
    "from session_metadata import incorrect_trials\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "required_keys = ['spikepow', 'threshcross', 'predaudio16k', 'cue']\n",
    "participant = 't15'\n",
    "session = 'XX'\n",
    "data_path = f'../data/{participant}/{session}/'\n",
    "savepath_fig = f'../figures/{participant}_pca/'\n",
    "if not os.path.exists(savepath_fig):\n",
    "    os.mkdir(savepath_fig)\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "nbins_before_onset = 10 # 100ms\n",
    "nbins_after_onset = 40 # 500ms\n",
    "n_channels = 256\n",
    "amplitudes = ['MIME', 'WHISPER', 'NORMAL', 'LOUD']\n",
    "words = ['be', 'my', 'know', 'do', 'have', 'going']\n",
    "amplitude_color = [\n",
    "    (167/255, 185/255, 207/255),\n",
    "    (114/255, 159/255, 207/255),\n",
    "    (53/255, 126/255, 221/255),\n",
    "    (0, 79/255, 158/255),\n",
    "]\n",
    "word_color = [\n",
    "    (0.9254902, 0.12156863, 0.14117647),\n",
    "    (0.98431373, 0.72941176, 0.07058824),\n",
    "    # [0.57254902, 0.78431373, 0.24313725],  # Commented out in MATLAB\n",
    "    (0.384, 0.682, 0.2),\n",
    "    (0.43137255, 0.79607843, 0.85490196),\n",
    "    # (0.26529412, 0.40686275, 0.72490196),\n",
    "    [0.45568627, 0.31764706, 0.63529412],  # Commented out in MATLAB\n",
    "    (0.84705882, 0.2627451, 0.59215686)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = {}\n",
    "for file in files:\n",
    "    name, extension = os.path.splitext(file)\n",
    "    if extension == '.mat':\n",
    "        fullPath = str(Path(data_path, file).resolve())\n",
    "        print(f'Loading {fullPath} ...')\n",
    "        data_temp = scipy.io.loadmat(fullPath)\n",
    "\n",
    "        # remove incorrect trials\n",
    "        curr_block = int(np.squeeze(data_temp['block_number']))\n",
    "        remove_trials = incorrect_trials[participant][session][curr_block] # trial ids, 1-indexed\n",
    "        print(f'Removing trials {remove_trials}')\n",
    "        remove_trial_inds = [i-1 for i in remove_trials] # trial indices, 0-indexed\n",
    "\n",
    "        data_temp_required = {}\n",
    "        for key in required_keys:\n",
    "            data_temp_required[key] = np.delete(data_temp[key], remove_trial_inds, axis = -1)\n",
    "\n",
    "        # append data to master dict\n",
    "        if data == {}:\n",
    "            data = data_temp_required\n",
    "        else:\n",
    "            for key in required_keys:\n",
    "                data[key] = np.append(data[key], data_temp_required[key], axis = -1)\n",
    "\n",
    "\n",
    "print('Data loaded ...')\n",
    "for key in data:\n",
    "    print(key, data[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spikepow around speech onset, get average spike for word-amp combination\n",
    "n_trials = len(data['cue'])\n",
    "word_amp_trial_avg = []\n",
    "word_label = []\n",
    "amp_label = []\n",
    "for word in words:\n",
    "    for amp in amplitudes:\n",
    "        print(word, amp)\n",
    "        inds = [k for k in range(n_trials) if amp in data['cue'][k] and \n",
    "                word in data['cue'][k] and max(np.squeeze(data['predaudio16k'])[k]) != 0]\n",
    "        \n",
    "        x_spikepow = np.empty((0, nbins_before_onset + nbins_after_onset, 256))\n",
    "        # x_threshcross = np.empty((0, nbins_before_onset + nbins_after_onset, 256))\n",
    "        for k in inds:\n",
    "                spikepow = np.squeeze(data['spikepow'])[k]\n",
    "                # threshcross = np.squeeze(data['threshcross'])[k]\n",
    "                start_ind, end_ind = get_audio_onset_offset(np.squeeze(data['predaudio16k'])[k].squeeze())\n",
    "                # binned start and end ind\n",
    "                start_ind = math.floor((start_ind/30000) * (1000/10)) # divide by sampling rate (30kHZ), scale it to ms by multiplying with 1000, divide by 10 to get bin index\n",
    "                end_ind = math.ceil((end_ind/30000) * (1000/10)) # divide by sampling rate (30kHZ), scale it to ms by multiplying with 1000, divide by 10 to get bin index\n",
    "\n",
    "                if np.expand_dims(spikepow[start_ind - nbins_before_onset: start_ind + nbins_after_onset, :], 0).shape[1] == nbins_before_onset + nbins_after_onset:\n",
    "                        # add spikepow and threshcross around speech onset\n",
    "                        temp_spikepow = spikepow[start_ind - nbins_before_onset: start_ind + nbins_after_onset, :] # shape (time_bins x 256)\n",
    "                        x_spikepow = np.append(x_spikepow, np.expand_dims(temp_spikepow, 0), axis = 0)\n",
    "\n",
    "        print(x_spikepow.shape)\n",
    "        x_spikepow_mean = np.mean(x_spikepow, axis = 0) # avg across trials\n",
    "        word_amp_trial_avg.append(x_spikepow_mean)\n",
    "        word_label.append(words.index(word))\n",
    "        amp_label.append(amplitudes.index(amp))\n",
    "\n",
    "amp_word_trial_avg = np.array(word_amp_trial_avg)\n",
    "print(amp_word_trial_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label_3d = np.zeros(amp_word_trial_avg.shape)\n",
    "amp_label_3d = np.zeros(amp_word_trial_avg.shape)\n",
    "for i in range(amp_word_trial_avg.shape[0]):\n",
    "    word_label_3d[i] = word_label[i] * np.ones((amp_word_trial_avg.shape[1], amp_word_trial_avg.shape[2]))\n",
    "    amp_label_3d[i] = amp_label[i] * np.ones((amp_word_trial_avg.shape[1], amp_word_trial_avg.shape[2]))\n",
    "print(word_label_3d.shape, amp_label_3d.shape, amp_word_trial_avg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_samples = n_trial x t, n_feat  = n_channels; plot after averaging across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pca all components, but take only 3 for plotting\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# no averaging across time; n_samples == n_conditions x time (25 x 50), n_features == n_channels (256)\n",
    "X = amp_word_trial_avg.reshape(-1, 256)\n",
    "print('PCA input shape:', X.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "x_pca = pca.fit_transform(X_scaled) \n",
    "print('PCA transformed shape:', x_pca.shape)\n",
    "\n",
    "x_pca_flatten_time_pca_on_ch = x_pca\n",
    "\n",
    "# reshape it back to n_trials x time x n_pca_components\n",
    "x_pca = x_pca.reshape(amp_word_trial_avg.shape[0], -1, 3)\n",
    "print('PCA reshaped back to n_trials x time x n_pca_feat:', x_pca.shape)\n",
    "# averge across time\n",
    "x_pca = np.mean(x_pca, axis=1)\n",
    "print('Average across time:', x_pca.shape)\n",
    "\n",
    "x_ax = x_pca[:, 0]\n",
    "y_ax = x_pca[:, 1]\n",
    "z_ax = x_pca[:, 2]\n",
    "\n",
    "print('PCA x_ax:', x_ax)\n",
    "print('PCA y_ax:', y_ax)\n",
    "print('PCA z_ax:', z_ax)\n",
    "\n",
    "\n",
    "# Create 3D scatter plot, legend based on amplitude\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x_ax, y=y_ax, z=z_ax,\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=np.array(amplitude_color)[amp_label], opacity=1),\n",
    ")])\n",
    "\n",
    "# Set layout options\n",
    "fig.update_layout(\n",
    "    title=\"Interactive 3D Scatter Plot\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"PC1\",\n",
    "        yaxis_title=\"PC2\",\n",
    "        zaxis_title=\"PC3\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PCA projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amplitude based color coding\n",
    "\n",
    "# uncomment to use ipympl backend and allow interactive 3D plotting\n",
    "# %matplotlib ipympl\n",
    "# fig = plt.figure(figsize=(5, 5))\n",
    "# fontsize = 10\n",
    "# scatter_size = 100\n",
    "\n",
    "fontsize = 26\n",
    "scatter_size = 1800\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_ax, y_ax, z_ax, color=np.array(amplitude_color)[amp_label], s=scatter_size, alpha = 0.8)\n",
    "ax.set_xlabel('PC 1', fontsize = fontsize)\n",
    "ax.set_ylabel('PC 2', fontsize = fontsize)\n",
    "ax.set_zlabel('PC 3', fontsize = fontsize)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "ax.view_init(elev = -75, azim = 118, roll = 177)\n",
    "ax.grid(False)\n",
    "\n",
    "mime_inds = np.where(np.array(amp_label) == 0)[0]\n",
    "mime_centroid = [sum(x_ax[mime_inds])/len(mime_inds), sum(y_ax[mime_inds])/len(mime_inds), sum(z_ax[mime_inds])/len(mime_inds)]\n",
    "loud_inds = np.where(np.array(amp_label) == 3)[0]\n",
    "loud_centroid = [sum(x_ax[loud_inds])/len(loud_inds), sum(y_ax[loud_inds])/len(loud_inds), sum(z_ax[loud_inds])/len(loud_inds)]\n",
    "# ax.plot3D([loud_centroid[0], mime_centroid[0]], [loud_centroid[1], mime_centroid[1]], [loud_centroid[2], mime_centroid[2]], 'black', linewidth = 7)\n",
    "\n",
    "fig.tight_layout()\n",
    "# save figure\n",
    "plt.savefig(f'{savepath_fig}{participant}_{session}_{formatted_datetime}_pca_amplitude.svg', format='svg', dpi=1200)\n",
    "plt.savefig(f'{savepath_fig}{participant}_{session}_{formatted_datetime}_pca_amplitude.png', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word based color coding\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_ax, y_ax, z_ax, color=np.array(word_color)[word_label], s=scatter_size, alpha = 0.8)\n",
    "ax.set_xlabel('PC 1', fontsize = fontsize)\n",
    "ax.set_ylabel('PC 2', fontsize = fontsize)\n",
    "ax.set_zlabel('PC 3', fontsize = fontsize)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "ax.view_init(elev = -75, azim = 118, roll = 177)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# save figure\n",
    "plt.savefig(f'{savepath_fig}{participant}_{session}_{formatted_datetime}_pca_word.svg', format='svg', dpi=1200)\n",
    "plt.savefig(f'{savepath_fig}{participant}_{session}_{formatted_datetime}_pca_word.png', format='png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
